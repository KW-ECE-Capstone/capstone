# Solution1_Communication

<img width="209" alt="image" src="https://user-images.githubusercontent.com/88064555/167590096-64ad112a-05e1-414a-b2f4-41318987fd20.png">

    통신을 이용하여 Why를 구현한 모델이다. 안드로이드에서 동영상과 카메라/마이크가 병행적으로 실행된다. 사용자가 입력한 제스쳐/음성을 받아들여 RTMP 서버로 송출한다.(서버는 WOWZA를 사용하였다.) 동시에 Python 클라이언트에서 서버로 송출된 제스쳐/음성을 가져온다. 충분히 학습된 데이터셋을 기반으로 가져온 제스쳐/음성을 판단하고 이를 명령어로 변환한다. 이를 다시, 안드로이드 클라이언트로 명령어를 반환하여 동영상을 제어한다.

---
## [Audio_Recognition_part]
+ 음성 인식부
+ 마이크로부터 사용자의 음성을 입력받아 명령어로 변환하여 명령어 분류부/적용부에 출력한다.

---
## [Gesture_Recognition_part]
+ 제스쳐 인식부
+ 카메라로부터 사용자의 제스쳐를 입력받아 명령어로 변환하여 명령어 분류부/적용부에 출력한다. 

---
## [Command_Application_part]
+ 명령어 분류부/적용부
+ 제스쳐/음성 인식부로부터 명령어를 입력 받아 동영상을 제어한다.

---
## [프로젝트 블록 다이어그램]
<img width="864" alt="스크린샷 2022-03-30 오전 3 32 08" src="https://user-images.githubusercontent.com/88064555/160681059-60287651-0453-441f-8509-bf327c3f328f.png">




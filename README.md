# 광운대학교 전자통신공학과 캡스톤 프로젝트

![03_03_문장_로고타입_조합_국영문_가로_1Color_typeB](https://user-images.githubusercontent.com/88064555/160678993-70372853-5ca5-42bf-85a6-de9f68d5f888.jpg)

----------
## 프로젝트 목적

+ Why: 레시피 영상이 요리 초보의 진도에 맞춰 재생되게 하고 싶다.
+ What: 레시피 영상이 요리 초보의 진도에 맞춰 재생되게 하는 시스템
+ How: 안드로이드 어플리케이션
---


## 프로젝트 설계도
---
<img width="864" alt="스크린샷 2022-03-30 오전 3 32 08" src="https://user-images.githubusercontent.com/88064555/160681059-60287651-0453-441f-8509-bf327c3f328f.png">

## 조원 및 역할
-----
+ 김진만 - 음성 인식부
+ 이정연 - 카메라/마이크, 명령어 분류부/적용부
+ 조시언 - 제스쳐 인식부
+ 최동혁 - 음성/제스쳐 통신부

## 폴더 설명
---
+ **Solution1_Communication**

    <img width="209" alt="image" src="https://user-images.githubusercontent.com/88064555/167547070-464eddce-374d-4903-ab27-0f8b1b99894f.png">

    통신을 이용하여 Why를 구현한 모델이다. 안드로이드에서 동영상과 카메라/마이크가 병행적으로 실행된다. 사용자가 입력한 제스쳐/음성을 받아들여 RTMP 서버로 송출한다.(서버는 WOWZA를 사용하였다.) 동시에 Python 클라이언트에서 서버로 송출된 제스쳐/음성을 가져온다. 충분히 학습된 데이터셋을 기반으로 가져온 제스쳐/음성을 판단하고 이를 명령어로 변환한다. 이를 다시, 안드로이드 클라이언트로 명령어를 반환하여 동영상을 제어한다.


+ **Solution2_Only_Android**

    <img width="165" alt="image" src="https://user-images.githubusercontent.com/88064555/167548145-e85c7c54-2327-45aa-8d17-bce473b41dd2.png">

    오직 안드로이드 개발환경만을 이용하여 블록 다이어그램을 구현한 모델이다. [솔루션 1]과 비교하였을 때 장점은 통신부를 제거하여 Delay 문제를 개선할 수 있다. 사용자가 입력한 제스쳐/음성을 별도의 서버로 송출하지 않고 안드로이드 앱 자체에서 해당 입력을 판단하여 이를 명령어로 변환하여 즉각적으로 동영상을 제어한다. 

+ **not_use**

    _백업용 폴더_

    현재 사용하지 않지만 혹시 모를 상황에 대비하여 백업을 위한 폴더이다. 프로젝트를 진행하며 폴더가 많아지면 헷갈리므로 안 쓰는 파일들을 여기에 저장한다.

## 디렉토리/파일 네이밍 규칙

+ 디렉토리: 첫 글자는 대문자로 시작하며 단어를 구분할 때는 underba(_)를 사용한다.

        ex) Directory_Naming_Rule

+ 파일: 모든 글자를 소문자로 하며 단어를 구분할 때는 underba(_)를 사용한다.

        ex) file_naming_rule

## 참고사항

안드로이드 프로젝트 파일은 용량 제한(100MB) 때문에 핵심 코드만 첨부하였다. 주로 MainActivity, XML, gradle 파일만 수정하였는데 기본 안드로이드 프로젝트에 해당 부분에 맞게 변경하여 적용하면 된다.


